---
phase: 63-llm-pipeline-overhaul
plan: 02
type: execute
wave: 2
depends_on: ["63-01"]
files_modified:
  - api/functions/llm-batch-generator.R
  - api/start_sysndd_api.R
autonomous: true
must_haves:
  truths:
    - "Clustering job triggers LLM batch generation"
    - "Summaries appear in llm_cluster_summary_cache table"
    - "GET /api/analysis/functional_cluster_summary returns 200 with data"
    - "GET /api/analysis/phenotype_cluster_summary returns 200 with data"
    - "All R tests pass (687 + 11 E2E)"
    - "API is fully linted (0 lintr issues)"
  artifacts:
    - path: "api/functions/llm-batch-generator.R"
      provides: "LLM batch generation executor"
      exports: ["trigger_llm_batch_generation", "llm_batch_executor"]
    - path: "api/endpoints/analysis_endpoints.R"
      provides: "LLM summary endpoints"
      contains: "functional_cluster_summary"
  key_links:
    - from: "api/functions/job-manager.R"
      to: "api/functions/llm-batch-generator.R"
      via: "promise callback after clustering"
      pattern: "trigger_llm_batch_generation"
    - from: "api/endpoints/analysis_endpoints.R"
      to: "api/functions/llm-cache-repository.R"
      via: "get_cached_summary"
      pattern: "get_cached_summary"
---

<objective>
Verify the LLM pipeline works end-to-end and ensure all tests and linting pass.

Purpose: Confirm that clustering triggers LLM generation, summaries are cached, and the API endpoints return summary data. Run full test and lint suite to ensure no regressions.

Output: Working LLM pipeline with cached summaries; 200 responses from summary endpoints; all 687 R tests + 11 E2E pass; lintr passes with 0 issues.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/63-llm-pipeline-overhaul/63-01-SUMMARY.md
@api/functions/llm-batch-generator.R
@api/functions/job-manager.R
@api/endpoints/analysis_endpoints.R
</context>

<tasks>

<task type="auto">
  <name>Task 1: Trigger Clustering and Verify LLM Pipeline</name>
  <files>None (testing task)</files>
  <action>
    With the Docker container running from Plan 01, test the LLM pipeline end-to-end:

    **Step 1: Check GEMINI_API_KEY is set**

    The clustering job triggers LLM generation only if GEMINI_API_KEY is set.
    Verify the environment variable is available in Docker:
    ```bash
    docker compose exec api printenv | grep GEMINI
    ```

    If not set, add it to docker-compose.dev.yml or .env file and restart:
    ```yaml
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    ```

    **Step 2: Trigger functional clustering job**

    Use the API to submit a clustering job:
    ```bash
    curl -X POST "http://localhost:7777/api/jobs/clustering/submit/" \
      -H "Content-Type: application/json" \
      -d '{"inheritance": "Autosomal dominant"}'
    ```

    Note the job_id from the response.

    **Step 3: Monitor job progress**

    Poll the job status until complete:
    ```bash
    JOB_ID="<job_id_from_step_2>"
    curl -s "http://localhost:7777/api/jobs/${JOB_ID}/" | jq
    ```

    Watch container logs for LLM batch generation messages:
    ```bash
    docker compose logs api -f --tail=100 | grep -E "LLM-Batch|LLM-Executor"
    ```

    Expected log messages:
    - "[LLM-Batch] Triggering for N functional clusters"
    - "[LLM-Batch] Job created successfully: <uuid>"
    - "[LLM-Executor] Processing N functional clusters"

    **Step 4: Verify summaries in database**

    Check if summaries were saved to cache:
    ```bash
    docker compose exec mysql mysql -u sysndd -ppassword sysndd_db \
      -e "SELECT cache_id, cluster_type, cluster_number, validation_status FROM llm_cluster_summary_cache LIMIT 10;"
    ```

    Should show rows with cluster summaries.

    **Step 5: Verify API endpoints return 200**

    Get a cluster hash from the database:
    ```bash
    docker compose exec mysql mysql -u sysndd -ppassword sysndd_db \
      -e "SELECT cluster_hash, cluster_number FROM llm_cluster_summary_cache WHERE cluster_type='functional' LIMIT 1;" -N
    ```

    Test the endpoint:
    ```bash
    HASH="<hash_from_query>"
    CLUSTER_NUM="<cluster_number>"
    curl -s "http://localhost:7777/api/analysis/functional_cluster_summary/?cluster_hash=${HASH}&cluster_number=${CLUSTER_NUM}" | jq
    ```

    Should return 200 with summary_json containing summary, key_themes, pathways, tags.

    **Troubleshooting:**

    If LLM generation fails, check:
    1. Container logs for specific error messages
    2. `/tmp/llm_executor_debug.log` inside container for detailed traces
    3. GEMINI_API_KEY validity (try direct API call)

    If generation succeeds but summaries don't appear:
    1. Check llm_cluster_summary_cache table for any rows
    2. Check llm_generation_log table for error entries
  </action>
  <verify>
    1. LLM batch job created:
       `docker compose logs api | grep "LLM-Batch.*Job created"` shows job UUID

    2. Summaries in database:
       `docker compose exec mysql mysql -u sysndd -ppassword sysndd_db -e "SELECT COUNT(*) FROM llm_cluster_summary_cache;" -N`
       Returns count > 0

    3. API returns 200:
       Test functional_cluster_summary endpoint returns 200 status code
  </verify>
  <done>
    Clustering triggers LLM generation; summaries appear in database;
    API endpoints return 200 with summary data.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run Full R Test Suite</name>
  <files>None (testing task)</files>
  <action>
    Run the complete R test suite to verify no regressions:

    **Step 1: Run unit tests**

    The test suite requires the database to be running. Use the Makefile target:
    ```bash
    cd /home/bernt-popp/development/sysndd
    make test-api
    ```

    This runs testthat tests with database connection.

    Expected outcome: 687 tests pass + 11 E2E tests pass.

    **Step 2: Check for test failures**

    If any tests fail:
    1. Note the failing test file and test name
    2. Check if failure is related to LLM changes (llm-*, analysis_endpoints)
    3. Fix any issues in the relevant files

    **Step 3: Run E2E tests specifically**

    E2E tests are in `tests/testthat/test-e2e-*.R`:
    ```bash
    cd /home/bernt-popp/development/sysndd/api
    Rscript -e "testthat::test_file('tests/testthat/test-e2e-user-lifecycle.R')"
    ```

    All 11 E2E tests should pass.

    **Common test issues to watch for:**
    - LLM tests may skip if GEMINI_API_KEY not set in test environment
    - Database connection tests need test database running
    - Mocked external API tests should pass regardless of network
  </action>
  <verify>
    Run: `make test-api` from project root.
    All tests should pass with output showing 687+ tests passing.
  </verify>
  <done>
    All 687 unit tests pass; all 11 E2E tests pass; no regressions introduced.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run Linting and Fix Any Issues</name>
  <files>Potentially any modified api/*.R files</files>
  <action>
    Run lintr to ensure code quality:

    **Step 1: Run API linting**

    ```bash
    cd /home/bernt-popp/development/sysndd
    make lint-api
    ```

    This runs lintr on all R files in the api/ directory.

    **Step 2: Fix any lint issues**

    If lintr reports issues, fix them:
    - Line length > 120 characters: break into multiple lines
    - Trailing whitespace: remove
    - Missing spaces around operators: add spaces
    - Unused variables: remove or comment with # nolint

    **Step 3: Run frontend linting**

    ```bash
    make lint-app
    ```

    Should pass with 0 issues.

    **Step 4: Run TypeScript type-check**

    ```bash
    cd /home/bernt-popp/development/sysndd/app
    npm run type-check
    ```

    Should pass with no type errors.

    **Step 5: Verify pre-commit passes**

    Run the full pre-commit check:
    ```bash
    cd /home/bernt-popp/development/sysndd
    make pre-commit
    ```

    This runs lintr + eslint + type-check without database.
  </action>
  <verify>
    1. `make lint-api` exits with code 0 (no lint issues)
    2. `make lint-app` exits with code 0 (no ESLint issues)
    3. `npm run type-check` exits with code 0 (no TypeScript errors)
  </verify>
  <done>
    API fully linted with 0 issues; frontend linted with 0 issues;
    TypeScript type-check passes.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **LLM Pipeline Works**:
   - Clustering job triggers LLM batch generation
   - Summaries appear in llm_cluster_summary_cache table
   - GET /api/analysis/functional_cluster_summary returns 200

2. **Tests Pass**:
   - 687 R unit tests pass
   - 11 E2E tests pass
   - No test regressions

3. **Linting Passes**:
   - `make lint-api` returns 0 issues
   - `make lint-app` returns 0 issues
   - `npm run type-check` passes

Run the full CI check locally:
```bash
make ci-local
```
This should pass all checks.
</verification>

<success_criteria>
- LLM-FIX-05: Clustering job triggers LLM batch generation successfully
- LLM-FIX-06: Summaries stored in llm_cluster_summary_cache table
- LLM-FIX-07: API endpoints return 200 with summary data
- All 687 R tests + 11 E2E tests pass
- API fully linted (0 lintr issues)
- Frontend linted (0 ESLint issues)
- TypeScript type-check passes
</success_criteria>

<output>
After completion, create `.planning/phases/63-llm-pipeline-overhaul/63-02-SUMMARY.md`
</output>
