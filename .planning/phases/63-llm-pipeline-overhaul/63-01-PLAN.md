---
phase: 63-llm-pipeline-overhaul
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - api/Dockerfile
  - api/functions/db-helpers.R
  - api/functions/llm-cache-repository.R
  - api/functions/llm-batch-generator.R
  - api/functions/llm-service.R
  - api/functions/llm-judge.R
autonomous: true
must_haves:
  truths:
    - "Docker build completes without ICU/stringi errors"
    - "Database operations work in both main process and mirai daemons"
    - "JSON serialization produces scalar strings for DBI parameter binding"
    - "Gemini model name is valid and API calls succeed"
  artifacts:
    - path: "api/Dockerfile"
      provides: "Docker build with ICU library compatibility"
      contains: "RENV_CONFIG_RSPM_ENABLED"
    - path: "api/functions/db-helpers.R"
      provides: "Daemon-safe database operations"
      contains: "daemon_db_conn"
    - path: "api/functions/llm-cache-repository.R"
      provides: "JSON serialization for DBI"
      contains: "as.character(jsonlite::toJSON"
  key_links:
    - from: "api/functions/llm-batch-generator.R"
      to: "api/functions/db-helpers.R"
      via: "daemon_db_conn global assignment"
      pattern: "daemon_db_conn"
    - from: "api/functions/llm-cache-repository.R"
      to: "DBI::dbBind"
      via: "as.character wrapped JSON"
      pattern: "as\\.character.*toJSON"
---

<objective>
Fix the foundation layer issues blocking LLM pipeline execution.

Purpose: Address root causes preventing Docker builds, database operations in daemons, and JSON serialization for SQL parameter binding. This is prerequisite work for LLM pipeline verification.

Output: Docker container that builds cleanly; database operations that work in mirai daemons; JSON serialization that produces scalar strings for DBI.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/LLM_PIPELINE_DEBUG_REPORT.md
@.planning/LLM_BATCH_DEBUG_STATUS.md
@.planning/phases/63-llm-pipeline-overhaul/63-RESEARCH.md
@api/Dockerfile
@api/functions/db-helpers.R
@api/functions/llm-cache-repository.R
@api/functions/llm-service.R
@api/functions/llm-judge.R
@api/functions/llm-batch-generator.R
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix Docker ICU Library Compatibility</name>
  <files>api/Dockerfile</files>
  <action>
    The Docker build fails with ICU library mismatch when using `--no-cache`:
    ```
    libicui18n.so.70: cannot open shared object file
    ```

    Fix the Dockerfile to ensure stringi package compatibility:

    1. Add environment variable to disable RSPM for packages that have ICU issues:
       - Add `ENV RENV_CONFIG_RSPM_ENABLED=FALSE` BEFORE the renv::restore() call
       - This forces source compilation which links against the container's ICU

    2. Alternative approach if source compilation is too slow:
       - Explicitly install ICU dev package: Already present as `libicu-dev` (line 65)
       - The issue is binary mismatch - forcing source fixes this

    3. Add ICU verification step after package installation:
       - Add `RUN R -e "library(stringi); cat(stri_info()[[1]])"` to verify stringi loads

    Location: In the "Stage 2: Packages" section, add the RENV_CONFIG_RSPM_ENABLED=FALSE
    environment variable before the renv::restore() call (around line 132).

    The rocker/r-ver:4.4.3 image uses Ubuntu 22.04 (jammy) with ICU 70, but RSPM binaries
    may be compiled against a different ICU version.
  </action>
  <verify>
    Run: `cd /home/bernt-popp/development/sysndd && docker compose build api --no-cache`
    Build should complete without ICU/stringi errors.
  </verify>
  <done>Docker build succeeds with `--no-cache` flag; stringi package loads correctly.</done>
</task>

<task type="auto">
  <name>Task 2: Fix Database Operations and JSON Serialization</name>
  <files>api/functions/db-helpers.R, api/functions/llm-cache-repository.R, api/functions/llm-service.R, api/functions/llm-judge.R</files>
  <action>
    Two interconnected issues to fix:

    **Issue A: "unused argument (envir = .GlobalEnv)" error**

    The debug reports show this error occurs in db_execute_query(). The existing code already
    uses `base::exists()`, `base::get()`, etc. The issue may be:
    1. Cached bytecode from old function definitions
    2. A different code path being executed

    Add entry-point logging to trace the actual execution:
    - In `db_execute_query()`: Add `message("[db_execute_query] ENTRY - sql: ", substr(sql, 1, 50))`
      at the very start of the function (line 116, after function signature).
    - In `get_db_connection()`: Add `message("[get_db_connection] ENTRY")` at line 28.

    This logging will help identify WHERE the error actually occurs.

    **Issue B: JSON serialization produces non-scalar for DBI**

    The error "Parameter 6 does not have length 1" occurs because `jsonlite::toJSON()`
    returns a `json` class object with attributes.

    Review `llm-cache-repository.R` and verify ALL `toJSON()` calls are wrapped:
    - Line ~201-204: `save_summary_to_cache` - already wrapped (verify)
    - Line ~207-212: tags_json_str - already wrapped (verify)
    - Line ~318-325: `log_generation_attempt` - already wrapped (verify)

    If any are not wrapped, fix them with `as.character(jsonlite::toJSON(...))`.

    **Issue C: Model name validity**

    Current code uses "gemini-3-pro-preview" which may not be a valid model.
    Update to use "gemini-2.0-flash" (the default and verified working model):
    - `llm-service.R` line ~275: change default model to "gemini-2.0-flash"
    - `llm-judge.R` line ~106: change default model to "gemini-2.0-flash"

    Note: Do NOT change the existing function signatures, just the default parameter value.
  </action>
  <verify>
    1. Verify logging added:
       `grep -n "db_execute_query.*ENTRY\|get_db_connection.*ENTRY" api/functions/db-helpers.R`

    2. Verify JSON wrapping:
       `grep -n "as.character.*toJSON" api/functions/llm-cache-repository.R`
       Should show lines ~204, ~212, ~324.

    3. Verify model name update:
       `grep -n "gemini-2.0-flash" api/functions/llm-service.R api/functions/llm-judge.R`
       Should show the default parameter values.
  </verify>
  <done>
    Entry-point logging added; all toJSON calls wrapped with as.character();
    model name updated to verified working "gemini-2.0-flash".
  </done>
</task>

<task type="auto">
  <name>Task 3: Rebuild Container and Verify Database Operations</name>
  <files>None (verification task)</files>
  <action>
    After the code fixes, rebuild the Docker container and verify database operations work:

    1. Rebuild container with no cache to ensure all changes are applied:
       ```bash
       cd /home/bernt-popp/development/sysndd
       docker compose build api --no-cache
       ```

    2. Start the API container:
       ```bash
       docker compose up -d api
       ```

    3. Verify database operations work by checking health endpoint:
       ```bash
       curl -s http://localhost:7777/api/health/ | jq
       ```
       Should return status "healthy".

    4. Check container logs for any startup errors:
       ```bash
       docker compose logs api --tail=50
       ```
       Should show "Database pool created" and "Started mirai daemon pool" without errors.

    5. Test database operations by hitting an endpoint that uses db_execute_query:
       ```bash
       curl -s "http://localhost:7777/api/entity/?page=1&limit=1" | jq '.data | length'
       ```
       Should return "1" (or a number indicating data was retrieved).

    If any errors occur, check:
    - Container logs for the actual error message
    - The entry-point logging added in Task 2 to trace the error source
  </action>
  <verify>
    1. Health check returns healthy:
       `curl -s http://localhost:7777/api/health/ | jq -r '.status'` returns "healthy"

    2. Entity endpoint returns data:
       `curl -s "http://localhost:7777/api/entity/?page=1&limit=1" | jq -r '.data | length'` returns "1"

    3. No errors in container startup:
       `docker compose logs api --tail=20` shows no ERROR messages
  </verify>
  <done>
    Docker container builds and starts successfully;
    database operations return data without "unused argument" errors.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Docker build passes**: `docker compose build api --no-cache` succeeds
2. **API starts cleanly**: `docker compose up -d api` starts without errors
3. **Health check passes**: `/api/health/` returns status "healthy"
4. **Database operations work**: `/api/entity/` returns entity data
5. **Logging shows trace**: Container logs show entry-point messages (if triggered)
</verification>

<success_criteria>
- LLM-FIX-01: Docker build completes without ICU/stringi errors
- LLM-FIX-02: Database operations work (entry-point logging added for debugging)
- LLM-FIX-03: JSON serialization verified to produce scalar strings
- LLM-FIX-04: Model name updated to verified working "gemini-2.0-flash"
- Foundation layer ready for LLM pipeline verification in Plan 02
</success_criteria>

<output>
After completion, create `.planning/phases/63-llm-pipeline-overhaul/63-01-SUMMARY.md`
</output>
