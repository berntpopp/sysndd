---
phase: 48-migration-auto-run-health
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - api/functions/migration-runner.R
  - api/start_sysndd_api.R
autonomous: true

must_haves:
  truths:
    - "API startup automatically applies pending migrations before serving requests"
    - "Multiple API workers coordinate via database lock (only one applies migrations)"
    - "API logs clearly show which migrations were applied on startup"
    - "API crashes on migration failure (forces fix before deploy)"
  artifacts:
    - path: "api/functions/migration-runner.R"
      provides: "Advisory lock functions for multi-worker coordination"
      exports: ["acquire_migration_lock", "release_migration_lock"]
    - path: "api/start_sysndd_api.R"
      provides: "Migration runner integration between pool creation and endpoint mounting"
      contains: "source.*migration-runner.R"
  key_links:
    - from: "api/start_sysndd_api.R"
      to: "api/functions/migration-runner.R"
      via: "source() call after pool creation"
      pattern: "source.*migration-runner\\.R"
    - from: "api/start_sysndd_api.R"
      to: "run_migrations()"
      via: "function call with lock coordination"
      pattern: "run_migrations.*conn.*pool"
---

<objective>
Integrate migration runner into API startup with multi-worker lock coordination

Purpose: Ensures database schema is always current before API serves requests. First worker to start acquires lock, applies pending migrations, releases lock. Other workers wait for lock then proceed (migrations already applied). API crashes on migration failure to force fix before deploy.

Output: Migration runner integration in start_sysndd_api.R, advisory lock functions in migration-runner.R, global migration_status variable for health endpoint access.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/48-migration-auto-run-health/48-CONTEXT.md
@.planning/phases/48-migration-auto-run-health/48-RESEARCH.md
@.planning/phases/47-migration-system-foundation/47-01-SUMMARY.md

# Source files to modify
@api/functions/migration-runner.R
@api/start_sysndd_api.R
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add advisory lock functions to migration-runner.R</name>
  <files>api/functions/migration-runner.R</files>
  <action>
Add two new exported functions to api/functions/migration-runner.R for MySQL advisory lock coordination:

1. `acquire_migration_lock(conn, lock_name = "sysndd_migration", timeout = 30)`:
   - Execute `SELECT GET_LOCK('sysndd_migration', 30) AS acquired` using DBI::dbGetQuery
   - Return TRUE on success (result$acquired == 1)
   - Stop with clear error on timeout (result$acquired == 0): "Migration lock acquisition timed out after {timeout} seconds"
   - Stop with clear error on database error (result$acquired is NA): "Migration lock acquisition failed: database error"
   - Log success: `log_info("Acquired migration lock '{lock_name}'")`

2. `release_migration_lock(conn, lock_name = "sysndd_migration")`:
   - Execute `SELECT RELEASE_LOCK('sysndd_migration') AS released` using DBI::dbGetQuery
   - Return TRUE if released (result$released == 1)
   - Log release: `log_info("Released migration lock '{lock_name}'")`
   - No error on "not held" case - just return FALSE

Add after the existing `record_migration()` function (around line 197).

Reference MySQL 8.0 GET_LOCK documentation for return values:
- 1 = lock acquired successfully
- 0 = lock acquisition timed out
- NULL = error (e.g., out of memory, thread killed)
  </action>
  <verify>
Verify the functions are syntactically correct:
```bash
docker exec sysndd_api Rscript -e "source('functions/migration-runner.R'); cat('Lock functions loaded successfully\n')"
```
  </verify>
  <done>
- acquire_migration_lock() acquires MySQL advisory lock with timeout
- release_migration_lock() releases MySQL advisory lock
- Both functions use parameterized lock_name for flexibility
- Clear error messages for timeout vs database error cases
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate migration runner into API startup</name>
  <files>api/start_sysndd_api.R</files>
  <action>
Add migration runner integration to api/start_sysndd_api.R between pool creation (line 187) and global objects (line 192). The integration point is immediately after the `pool <<- dbPool(...)` block.

1. Source migration-runner.R:
```r
source("functions/migration-runner.R", local = TRUE)
```

2. Add migration execution block with lock coordination:
```r
## -------------------------------------------------------------------##
# 7.5) Run database migrations with lock coordination
## -------------------------------------------------------------------##
tryCatch({
  # Checkout connection for lock duration (separate from pool operations)
  migration_conn <- pool::poolCheckout(pool)
  on.exit(pool::poolReturn(migration_conn), add = TRUE)

  # Acquire advisory lock (blocks until available or 30s timeout)
  acquire_migration_lock(migration_conn, timeout = 30)
  on.exit(release_migration_lock(migration_conn), add = TRUE)

  # Run migrations
  start_time <- Sys.time()
  result <- run_migrations(migrations_dir = "db/migrations", conn = pool)
  duration <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))

  # Log summary based on what happened
  if (result$newly_applied > 0) {
    message(sprintf("[%s] Migrations complete (%d applied in %.2fs): %s",
                    Sys.time(), result$newly_applied, duration,
                    paste(result$filenames, collapse = ", ")))
  } else {
    message(sprintf("[%s] Schema up to date (%d migrations applied)",
                    Sys.time(), result$total_applied))
  }

  # Store result for health endpoint access (global variable)
  migration_status <<- list(
    pending_migrations = 0,
    total_migrations = result$total_applied,
    last_run = Sys.time(),
    newly_applied = result$newly_applied,
    filenames = result$filenames
  )

}, error = function(e) {
  message(sprintf("[%s] FATAL: Migration failed - %s", Sys.time(), e$message))
  # Crash API - forces fix before deploy
  stop(paste("API startup aborted: migration failure -", e$message))
})
```

Key implementation notes:
- Use poolCheckout to get dedicated connection for lock (not pool directly)
- Use on.exit() chains for guaranteed cleanup (connection return, lock release)
- Store migration_status as global (<<-) for health endpoint access
- Use message() for startup logging (consistent with existing startup messages)
- Crash (stop()) on any migration error - no partial startup
  </action>
  <verify>
Verify API starts successfully with migrations (requires running database):
```bash
# Check startup logs for migration message
docker logs sysndd_api 2>&1 | grep -E "(Schema up to date|Migrations complete|Migration failed)" | tail -5
```
  </verify>
  <done>
- migration-runner.R sourced after pool creation
- Advisory lock acquired before migration execution
- Lock released after migrations (even on error via on.exit)
- migration_status global variable set for health endpoint
- Startup logs show migration status
- API crashes on migration failure with clear error message
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. **Verify migration integration exists:**
   ```bash
   grep -n "migration-runner.R" api/start_sysndd_api.R
   grep -n "migration_status" api/start_sysndd_api.R
   ```

2. **Verify lock functions exist:**
   ```bash
   grep -n "acquire_migration_lock\|release_migration_lock" api/functions/migration-runner.R
   ```

3. **Verify API starts with migration logging:**
   ```bash
   docker restart sysndd_api && sleep 5
   docker logs sysndd_api 2>&1 | tail -20
   ```
   Should show either "Schema up to date" or "Migrations complete".
</verification>

<success_criteria>
1. API startup automatically runs migration check
2. Migration lock acquired/released properly (visible in logs)
3. migration_status global variable accessible
4. API crashes on migration failure (tested by intentionally breaking a migration)
5. Multiple workers coordinate via lock (only one applies migrations)
</success_criteria>

<output>
After completion, create `.planning/phases/48-migration-auto-run-health/48-01-SUMMARY.md`
</output>
