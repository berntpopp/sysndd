---
phase: 71-viewlogs-database-filtering
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - db/migrations/011_logging_indexes.sql
autonomous: true

must_haves:
  truths:
    - "Index on timestamp enables fast date range queries"
    - "Index on status enables fast status filtering"
    - "Index on path enables fast path prefix filtering"
    - "Composite indexes support common multi-column filters"
  artifacts:
    - path: "db/migrations/011_logging_indexes.sql"
      provides: "Database indexes for logging table"
      contains: "CREATE INDEX"
  key_links:
    - from: "db/migrations/011_logging_indexes.sql"
      to: "logging table"
      via: "CREATE INDEX statements"
      pattern: "idx_logging_"
---

<objective>
Add database indexes to the logging table to support efficient database-side filtering.

Purpose: The logging table will be queried with WHERE clauses on timestamp, status, and path columns. Without indexes, MySQL performs full table scans which become slow as the table grows to 1M+ rows.

Output: Migration file `011_logging_indexes.sql` that adds 5 indexes (IDX-01 through IDX-05).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/71-viewlogs-database-filtering/71-RESEARCH.md

# Logging table schema (from db/15_Rcommands_sysndd_db_logging_table.R):
# - id INT AUTO_INCREMENT PRIMARY KEY
# - timestamp DATETIME NOT NULL
# - address VARCHAR(255) NOT NULL
# - agent TEXT
# - host VARCHAR(255)
# - request_method VARCHAR(10)
# - path TEXT
# - query TEXT
# - post TEXT
# - status INT
# - duration FLOAT
# - file VARCHAR(255)
# - modified TIMESTAMP

# Migration system:
@api/functions/migration-runner.R

# Existing migrations for pattern reference:
@db/migrations/006_add_llm_summary_cache.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create logging indexes migration file</name>
  <files>db/migrations/011_logging_indexes.sql</files>
  <action>
Create migration file `db/migrations/011_logging_indexes.sql` with the following indexes:

1. **IDX-01**: Single-column index on timestamp for date range queries
   ```sql
   CREATE INDEX IF NOT EXISTS idx_logging_timestamp ON logging(timestamp);
   ```

2. **IDX-02**: Single-column index on status for status filtering
   ```sql
   CREATE INDEX IF NOT EXISTS idx_logging_status ON logging(status);
   ```

3. **IDX-03**: Prefix index on path for path prefix filtering
   - Use path(100) prefix since path is TEXT type and full-length index would be too large
   - MySQL can use this for LIKE 'prefix%' queries
   ```sql
   CREATE INDEX IF NOT EXISTS idx_logging_path ON logging(path(100));
   ```

4. **IDX-04**: Composite index on (timestamp, status) for combined filtering
   - Column order matters: timestamp first since it has higher cardinality
   ```sql
   CREATE INDEX IF NOT EXISTS idx_logging_timestamp_status ON logging(timestamp, status);
   ```

5. **IDX-05**: Composite index on (id DESC, status) for paginated filtered queries
   - id DESC for efficient ORDER BY id DESC LIMIT/OFFSET with status filter
   ```sql
   CREATE INDEX IF NOT EXISTS idx_logging_id_desc_status ON logging(id DESC, status);
   ```

Include a header comment explaining the migration purpose. Use IF NOT EXISTS for idempotency.

Follow the pattern from existing migrations (see 006_add_llm_summary_cache.sql).
  </action>
  <verify>
File exists at db/migrations/011_logging_indexes.sql and contains all 5 CREATE INDEX statements:
```bash
grep -c "CREATE INDEX" db/migrations/011_logging_indexes.sql
# Should output: 5

grep "idx_logging_timestamp" db/migrations/011_logging_indexes.sql
grep "idx_logging_status" db/migrations/011_logging_indexes.sql
grep "idx_logging_path" db/migrations/011_logging_indexes.sql
grep "idx_logging_timestamp_status" db/migrations/011_logging_indexes.sql
grep "idx_logging_id_desc_status" db/migrations/011_logging_indexes.sql
```
  </verify>
  <done>
Migration file exists with 5 indexes covering:
- IDX-01: timestamp (date range queries)
- IDX-02: status (status filtering)
- IDX-03: path(100) prefix (path prefix filtering)
- IDX-04: timestamp + status composite
- IDX-05: id DESC + status composite (filtered pagination)
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify migration file syntax</name>
  <files>db/migrations/011_logging_indexes.sql</files>
  <action>
Verify the migration file has valid SQL syntax by checking:

1. All statements end with semicolons
2. IF NOT EXISTS clause is present on all CREATE INDEX statements
3. Table name is "logging" (not "logs" or other variants)
4. Index names follow the existing pattern (idx_tablename_column)
5. The path index uses prefix syntax: path(100)

Run a basic syntax check using the migration runner's split_sql_statements function pattern:
- File should have exactly 5 non-empty statements after splitting on semicolons
  </action>
  <verify>
```bash
# Count semicolons (should be 5)
grep -o ";" db/migrations/011_logging_indexes.sql | wc -l

# Verify all have IF NOT EXISTS
grep -c "IF NOT EXISTS" db/migrations/011_logging_indexes.sql
# Should output: 5

# Verify table name is logging
grep -c "ON logging" db/migrations/011_logging_indexes.sql
# Should output: 5
```
  </verify>
  <done>
Migration file passes syntax validation:
- 5 CREATE INDEX statements with semicolons
- All use IF NOT EXISTS for idempotency
- All target the "logging" table
  </done>
</task>

</tasks>

<verification>
1. File db/migrations/011_logging_indexes.sql exists
2. Contains exactly 5 CREATE INDEX IF NOT EXISTS statements
3. All indexes target the "logging" table
4. Index names follow pattern: idx_logging_*
5. Path index uses prefix: path(100)
</verification>

<success_criteria>
- Migration file 011_logging_indexes.sql created in db/migrations/
- File contains indexes for: timestamp, status, path(100), timestamp+status, id DESC+status
- All CREATE INDEX statements use IF NOT EXISTS for idempotency
- Requirements IDX-01 through IDX-05 satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/71-viewlogs-database-filtering/71-01-SUMMARY.md`
</output>
