---
phase: 72-documentation-testing
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/DEPLOYMENT.md
  - CLAUDE.md
autonomous: true
user_setup: []

must_haves:
  truths:
    - "docs/DEPLOYMENT.md documents MIRAI_WORKERS environment variable"
    - "DEPLOYMENT.md includes server profiles for small (4-8GB), medium (16GB), large (32GB+) servers"
    - "DEPLOYMENT.md includes recommended MIRAI_WORKERS values per profile"
    - "CLAUDE.md has Memory Configuration section explaining worker tuning"
  artifacts:
    - path: "docs/DEPLOYMENT.md"
      provides: "Deployment guide with memory configuration"
      min_lines: 80
    - path: "CLAUDE.md"
      provides: "Updated developer guide with memory section"
      contains: "Memory Configuration"
  key_links:
    - from: "docs/DEPLOYMENT.md"
      to: "docker-compose.yml"
      via: "References MIRAI_WORKERS env var"
      pattern: "MIRAI_WORKERS"
    - from: "CLAUDE.md"
      to: "docs/DEPLOYMENT.md"
      via: "Cross-reference for detailed info"
      pattern: "DEPLOYMENT.md"
---

<objective>
Create deployment documentation with memory configuration profiles and update CLAUDE.md with a memory configuration section.

Purpose: Operators deploying SysNDD need guidance on configuring worker count for their server's memory constraints. Developers need quick reference in CLAUDE.md.

Output: New docs/DEPLOYMENT.md file and updated CLAUDE.md with memory section.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/72-documentation-testing/72-RESEARCH.md

# Current developer guide (to be updated):
@CLAUDE.md

# Implementation details for documentation:
@.planning/phases/69-configurable-workers/69-01-PLAN.md (MIRAI_WORKERS implementation)
@docker-compose.yml (for env var reference)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create docs/DEPLOYMENT.md with memory configuration</name>
  <files>docs/DEPLOYMENT.md</files>
  <action>
Create the `docs/` directory if it doesn't exist, then create `docs/DEPLOYMENT.md`:

```markdown
# SysNDD Deployment Guide

**Last Updated:** 2026-02-XX
**Applies to:** SysNDD API v2.x

This guide covers deployment configuration for the SysNDD API, with focus on memory optimization for different server sizes.

## Quick Start

For most deployments, the defaults work well:

```bash
# Clone and configure
git clone https://github.com/your-org/sysndd.git
cd sysndd
cp .env.example .env

# Start with Docker Compose
docker compose up -d
```

## Memory Configuration

The SysNDD API uses [mirai](https://github.com/shikokuchuo/mirai) for background task processing (gene cluster analysis, LLM summaries, etc.). Each worker consumes memory proportional to the data it processes.

### MIRAI_WORKERS Environment Variable

Controls the number of background worker processes.

| Setting | Default | Range | Description |
|---------|---------|-------|-------------|
| `MIRAI_WORKERS` | 2 (prod), 1 (dev) | 1-8 | Number of mirai daemon workers |

**Configuration:**

```yaml
# docker-compose.yml
services:
  api:
    environment:
      MIRAI_WORKERS: ${MIRAI_WORKERS:-2}
```

Or via `.env` file:

```bash
MIRAI_WORKERS=2
```

### Server Profiles

Choose a profile based on your server's available RAM:

#### Small Server (4-8GB RAM)

Best for: Development, testing, low-traffic deployments

```yaml
# .env
MIRAI_WORKERS=1
DB_POOL_SIZE=3
```

**Expected behavior:**
- Memory usage: ~2-3GB peak during cluster analysis
- Concurrent analysis: Limited to 1 at a time
- Response time: Slightly slower for large gene sets

#### Medium Server (16GB RAM)

Best for: Production with moderate traffic

```yaml
# .env
MIRAI_WORKERS=2
DB_POOL_SIZE=5
```

**Expected behavior:**
- Memory usage: ~4-6GB peak
- Concurrent analysis: 2 parallel operations
- Response time: Good balance of speed and resource usage

#### Large Server (32GB+ RAM)

Best for: High-traffic production, research institutions

```yaml
# .env
MIRAI_WORKERS=4
DB_POOL_SIZE=10
```

**Expected behavior:**
- Memory usage: ~8-12GB peak
- Concurrent analysis: 4 parallel operations
- Response time: Fast for all operations

### Memory Calculation

Each mirai worker can consume up to:
- **Cluster analysis:** 1-2GB per worker (depends on gene set size)
- **LLM summaries:** 500MB per worker
- **Base overhead:** ~500MB for API process

**Formula:**
```
Peak Memory = Base (500MB) + Workers × 2GB
```

| Workers | Estimated Peak | Recommended Server RAM |
|---------|---------------|----------------------|
| 1 | ~2.5GB | 4-8GB |
| 2 | ~4.5GB | 8-16GB |
| 4 | ~8.5GB | 16-32GB |
| 8 | ~16.5GB | 32GB+ |

### Monitoring

Check current worker configuration via the health endpoint:

```bash
curl http://localhost:8000/api/health/performance | jq '.workers'
```

Response includes:
- `configured`: Number of workers configured via MIRAI_WORKERS
- `connections`: Active worker connections

### Troubleshooting

**Symptom: API crashes during cluster analysis**
- Cause: Insufficient memory for workers
- Solution: Reduce `MIRAI_WORKERS` or increase server RAM

**Symptom: Slow response times for analysis**
- Cause: Too few workers for concurrent requests
- Solution: Increase `MIRAI_WORKERS` if memory allows

**Symptom: Workers = 2 but I set MIRAI_WORKERS=10**
- Cause: Value bounded to maximum of 8
- Solution: Maximum is 8 workers; for more parallelism, scale horizontally

## Database Configuration

### DB_POOL_SIZE

Controls the database connection pool size.

| Setting | Default | Range | Description |
|---------|---------|-------|-------------|
| `DB_POOL_SIZE` | 5 | 3-20 | Database connection pool size |

**Recommendation:** Set to `MIRAI_WORKERS × 2 + 3` to ensure workers don't wait for connections.

| MIRAI_WORKERS | Recommended DB_POOL_SIZE |
|---------------|-------------------------|
| 1 | 3-5 |
| 2 | 5-7 |
| 4 | 10-12 |
| 8 | 18-20 |

## Docker Compose Files

SysNDD includes multiple compose files for different environments:

| File | Purpose | Default MIRAI_WORKERS |
|------|---------|----------------------|
| `docker-compose.yml` | Production | 2 |
| `docker-compose.override.yml` | Development override | 1 |
| `docker-compose.dev.yml` | Database-only (local API dev) | N/A |

**Production deployment:**
```bash
docker compose -f docker-compose.yml up -d
```

**Development (with override):**
```bash
docker compose up -d  # Uses override automatically
```

## Environment Variables Reference

### Required

| Variable | Description |
|----------|-------------|
| `PASSWORD` | API admin password |
| `MYSQL_ROOT_PASSWORD` | Database root password |

### Optional (with defaults)

| Variable | Default | Description |
|----------|---------|-------------|
| `MIRAI_WORKERS` | 2 | Background worker count |
| `DB_POOL_SIZE` | 5 | Database connection pool |
| `CORS_ALLOWED_ORIGINS` | (none) | CORS allowed origins |
| `GEMINI_API_KEY` | (none) | Google Gemini API key for LLM features |

## Health Checks

### Basic Health
```bash
curl http://localhost:8000/health
```

### Performance Stats
```bash
curl http://localhost:8000/api/health/performance
```

Includes:
- Worker status (configured count, active connections)
- Database pool stats
- Memory usage

---

*For development setup, see [CLAUDE.md](../CLAUDE.md)*
*For API documentation, see [/api/docs](http://localhost:8000/__docs__/)*
```

Key points:
- Create `docs/` directory first
- Include clear server profiles (small/medium/large)
- Document the memory calculation formula
- Include troubleshooting section
- Cross-reference CLAUDE.md
  </action>
  <verify>
```bash
# Directory and file exist
test -d docs && echo "docs/ exists"
test -f docs/DEPLOYMENT.md && echo "DEPLOYMENT.md exists"

# Contains required sections
grep "MIRAI_WORKERS" docs/DEPLOYMENT.md
grep "Small Server" docs/DEPLOYMENT.md
grep "Medium Server" docs/DEPLOYMENT.md
grep "Large Server" docs/DEPLOYMENT.md
grep "Memory Calculation" docs/DEPLOYMENT.md
```
  </verify>
  <done>
- docs/DEPLOYMENT.md exists with comprehensive deployment guide
- Documents MIRAI_WORKERS configuration (DOC-01)
- Includes server profiles for small/medium/large (DOC-02)
- Includes memory calculation and troubleshooting
  </done>
</task>

<task type="auto">
  <name>Task 2: Update CLAUDE.md with Memory Configuration section</name>
  <files>CLAUDE.md</files>
  <action>
Read the existing CLAUDE.md and add a "Memory Configuration" section after the "Database" section.

Add this new section:

```markdown
## Memory Configuration

### Worker Tuning

The API uses mirai workers for background tasks. Tune based on server RAM:

| Server RAM | MIRAI_WORKERS | Use Case |
|------------|---------------|----------|
| 4-8GB | 1 | Development, testing |
| 16GB | 2 | Production (default) |
| 32GB+ | 4 | High-traffic production |

```bash
# Check current configuration
curl http://localhost:8000/api/health/performance | jq '.workers'
```

### Quick Reference

```bash
# Small server (4-8GB RAM)
MIRAI_WORKERS=1 docker compose up -d

# Medium server (16GB RAM) - default
docker compose up -d

# Large server (32GB+ RAM)
MIRAI_WORKERS=4 docker compose up -d
```

For detailed deployment configuration, see [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md).
```

Insert this section after the "Database" section and before "Common Issues".
  </action>
  <verify>
```bash
# Check CLAUDE.md has new section
grep "Memory Configuration" CLAUDE.md
grep "Worker Tuning" CLAUDE.md
grep "MIRAI_WORKERS" CLAUDE.md
grep "DEPLOYMENT.md" CLAUDE.md
```
  </verify>
  <done>
- CLAUDE.md updated with Memory Configuration section (DOC-03)
- Includes quick reference table for server sizes
- Cross-references docs/DEPLOYMENT.md for details
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **docs/DEPLOYMENT.md exists with required content:**
   ```bash
   test -f docs/DEPLOYMENT.md && echo "DEPLOYMENT.md exists"
   grep -c "MIRAI_WORKERS\|Small Server\|Medium Server\|Large Server" docs/DEPLOYMENT.md
   ```

2. **CLAUDE.md has Memory Configuration section:**
   ```bash
   grep -A 5 "Memory Configuration" CLAUDE.md
   ```

3. **Cross-references work:**
   ```bash
   grep "DEPLOYMENT.md" CLAUDE.md
   grep "CLAUDE.md" docs/DEPLOYMENT.md
   ```

4. **Markdown is valid (no syntax errors):**
   ```bash
   # Quick syntax check - tables should have proper format
   grep -E "^\|.*\|.*\|" docs/DEPLOYMENT.md | head -5
   grep -E "^\|.*\|.*\|" CLAUDE.md | head -5
   ```
</verification>

<success_criteria>
Requirements coverage:
- [x] DOC-01: docs/DEPLOYMENT.md documents MIRAI_WORKERS configuration
- [x] DOC-02: Deployment profiles for small (4-8GB), medium (16GB), large (32GB+) servers
- [x] DOC-03: CLAUDE.md updated with memory configuration section

Observable behaviors:
1. docs/DEPLOYMENT.md exists with ~100+ lines of deployment guidance
2. DEPLOYMENT.md includes clear server profiles with recommended values
3. CLAUDE.md has new Memory Configuration section
4. Documents cross-reference each other
</success_criteria>

<output>
After completion, create `.planning/phases/72-documentation-testing/72-03-SUMMARY.md`
</output>
