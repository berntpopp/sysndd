---
phase: 64-llm-admin-dashboard
plan: 03
type: execute
wave: 2
depends_on: ["64-01"]
files_modified:
  - app/src/types/llm.ts
  - app/src/composables/useLlmAdmin.ts
  - app/src/router/routes.ts
autonomous: true

must_haves:
  truths:
    - "TypeScript interfaces exist for all LLM admin API responses"
    - "useLlmAdmin composable provides all API methods"
    - "ManageLLM route exists with Administrator-only access"
    - "Type-safe API calls work from frontend"
  artifacts:
    - path: "app/src/types/llm.ts"
      provides: "TypeScript interfaces for LLM admin"
      exports: ["LlmConfig", "PromptTemplate", "CacheStats", "CachedSummary", "GenerationLog", "RegenerationJob"]
    - path: "app/src/composables/useLlmAdmin.ts"
      provides: "Composable for LLM admin API calls"
      exports: ["useLlmAdmin"]
    - path: "app/src/router/routes.ts"
      provides: "ManageLLM route definition"
      contains: "ManageLLM"
  key_links:
    - from: "app/src/composables/useLlmAdmin.ts"
      to: "app/src/types/llm.ts"
      via: "type imports"
      pattern: "import.*from.*types/llm"
    - from: "app/src/composables/useLlmAdmin.ts"
      to: "api/endpoints/llm_admin_endpoints.R"
      via: "HTTP requests"
      pattern: "api/llm"
---

<objective>
Create frontend foundation for LLM admin dashboard

Purpose: Establish TypeScript interfaces, API composable, and routing for the LLM admin dashboard, enabling type-safe API integration.

Output: Types file, useLlmAdmin composable, and route definition ready for UI components
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/64-llm-admin-dashboard/64-RESEARCH.md
@.planning/LLM_ADMIN_DASHBOARD_PLAN.md
@app/src/composables/useAsyncJob.ts (existing job tracking pattern)
@app/src/router/routes.ts (routing pattern)
@app/src/views/admin/ManageAnnotations.vue (admin view reference)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TypeScript interfaces for LLM admin API</name>
  <files>app/src/types/llm.ts</files>
  <action>
Create new file app/src/types/llm.ts with comprehensive TypeScript interfaces:

```typescript
// app/src/types/llm.ts
// TypeScript interfaces for LLM Administration API

/**
 * LLM Configuration from GET /api/llm/config
 */
export interface LlmConfig {
  gemini_configured: boolean;
  current_model: string;
  available_models: GeminiModel[];
  rate_limit: RateLimitConfig;
}

export interface GeminiModel {
  model_id: string;
  display_name: string;
  description: string;
  rpm_limit: number;
  rpd_limit: number | null;
  recommended_for: string;
}

export interface RateLimitConfig {
  capacity: number;
  fill_time_s: number;
  backoff_base: number;
  max_retries: number;
}

/**
 * Prompt Template Types
 */
export type PromptType =
  | 'functional_generation'
  | 'functional_judge'
  | 'phenotype_generation'
  | 'phenotype_judge';

export interface PromptTemplate {
  template_id: number | null;
  prompt_type: PromptType;
  version: string;
  template_text: string;
  description: string | null;
}

export type PromptTemplates = Record<PromptType, PromptTemplate>;

/**
 * Cache Statistics from GET /api/llm/cache/stats
 */
export interface CacheStats {
  total_entries: number;
  by_status: {
    pending: number;
    validated: number;
    rejected: number;
  };
  by_type: {
    functional?: CacheTypeStats;
    phenotype?: CacheTypeStats;
  };
  last_generation: string | null;
  total_tokens_used: number;
  estimated_cost_usd: number;
}

export interface CacheTypeStats {
  count: number;
  validated: number;
  pending: number;
  rejected: number;
}

/**
 * Cached Summary from GET /api/llm/cache/summaries
 */
export type ValidationStatus = 'pending' | 'validated' | 'rejected';
export type ClusterType = 'functional' | 'phenotype';

export interface CachedSummary {
  cache_id: number;
  cluster_type: ClusterType;
  cluster_number: number;
  cluster_hash: string;
  model_name: string;
  prompt_version: string;
  summary_json: Record<string, unknown>;
  tags: string[] | null;
  is_current: boolean;
  validation_status: ValidationStatus;
  created_at: string;
  validated_at: string | null;
  validated_by: number | null;
}

export interface PaginatedCacheSummaries {
  data: CachedSummary[];
  total: number;
  page: number;
  per_page: number;
}

/**
 * Generation Log from GET /api/llm/logs
 */
export type LogStatus = 'success' | 'validation_failed' | 'api_error' | 'timeout';

export interface GenerationLog {
  log_id: number;
  cluster_type: ClusterType;
  cluster_number: number;
  cluster_hash: string;
  model_name: string;
  prompt_text: string;
  response_json: Record<string, unknown> | null;
  validation_errors: string | null;
  tokens_input: number | null;
  tokens_output: number | null;
  latency_ms: number | null;
  status: LogStatus;
  error_message: string | null;
  created_at: string;
}

export interface PaginatedLogs {
  data: GenerationLog[];
  total: number;
  page: number;
}

/**
 * Regeneration Job from POST /api/llm/regenerate
 */
export interface RegenerationJobResponse {
  job_id: string;
  status: string;
  cluster_type: ClusterType | 'all';
  force: boolean;
  status_url: string;
}

/**
 * Cache Clear Response from DELETE /api/llm/cache
 */
export interface CacheClearResponse {
  success: boolean;
  cleared_count: number;
  cluster_type: ClusterType | 'all';
}

/**
 * Validation Update Response from POST /api/llm/cache/:id/validate
 */
export interface ValidationUpdateResponse {
  success: boolean;
  cache_id: number;
  new_status: ValidationStatus;
}

/**
 * Model Update Response from PUT /api/llm/config
 */
export interface ModelUpdateResponse {
  success: boolean;
  current_model: string;
}

/**
 * Prompt Update Response from PUT /api/llm/prompts/:type
 */
export interface PromptUpdateResponse {
  success: boolean;
  type: PromptType;
  version: string;
  template_id: number;
}
```
  </action>
  <verify>
Run: cd /home/bernt-popp/development/sysndd/app && npx tsc --noEmit src/types/llm.ts
Should complete with no type errors.
  </verify>
  <done>
app/src/types/llm.ts exists with all required interfaces, passes TypeScript compilation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create useLlmAdmin composable for API calls</name>
  <files>app/src/composables/useLlmAdmin.ts</files>
  <action>
Create new file app/src/composables/useLlmAdmin.ts following existing composable patterns:

```typescript
// app/src/composables/useLlmAdmin.ts
// Composable for LLM Administration API calls

import { ref, readonly, type Ref } from 'vue';
import axios from 'axios';
import type {
  LlmConfig,
  PromptTemplates,
  PromptType,
  CacheStats,
  PaginatedCacheSummaries,
  PaginatedLogs,
  CacheClearResponse,
  RegenerationJobResponse,
  ValidationUpdateResponse,
  ModelUpdateResponse,
  PromptUpdateResponse,
  ClusterType,
  ValidationStatus,
  LogStatus,
} from '@/types/llm';

const API_BASE = `${import.meta.env.VITE_API_URL}/api/llm`;

export interface UseLlmAdminReturn {
  // State
  config: Readonly<Ref<LlmConfig | null>>;
  prompts: Readonly<Ref<PromptTemplates | null>>;
  cacheStats: Readonly<Ref<CacheStats | null>>;
  loading: Readonly<Ref<boolean>>;
  error: Readonly<Ref<string | null>>;

  // Config actions
  fetchConfig: (token: string) => Promise<void>;
  updateModel: (token: string, model: string) => Promise<ModelUpdateResponse>;

  // Prompt actions
  fetchPrompts: (token: string) => Promise<void>;
  updatePrompt: (
    token: string,
    type: PromptType,
    template: string,
    version: string,
    description?: string
  ) => Promise<PromptUpdateResponse>;

  // Cache actions
  fetchCacheStats: (token: string) => Promise<void>;
  fetchCachedSummaries: (
    token: string,
    params?: {
      cluster_type?: ClusterType;
      validation_status?: ValidationStatus;
      page?: number;
      per_page?: number;
    }
  ) => Promise<PaginatedCacheSummaries>;
  clearCache: (
    token: string,
    clusterType: ClusterType | 'all'
  ) => Promise<CacheClearResponse>;
  updateValidationStatus: (
    token: string,
    cacheId: number,
    action: 'validate' | 'reject'
  ) => Promise<ValidationUpdateResponse>;

  // Regeneration actions
  triggerRegeneration: (
    token: string,
    clusterType: ClusterType | 'all',
    force?: boolean
  ) => Promise<RegenerationJobResponse>;

  // Log actions
  fetchLogs: (
    token: string,
    params?: {
      cluster_type?: ClusterType;
      status?: LogStatus;
      from_date?: string;
      to_date?: string;
      page?: number;
      per_page?: number;
    }
  ) => Promise<PaginatedLogs>;
}

export function useLlmAdmin(): UseLlmAdminReturn {
  // Reactive state
  const config = ref<LlmConfig | null>(null);
  const prompts = ref<PromptTemplates | null>(null);
  const cacheStats = ref<CacheStats | null>(null);
  const loading = ref(false);
  const error = ref<string | null>(null);

  // Helper for auth headers
  const authHeaders = (token: string) => ({
    Authorization: `Bearer ${token}`,
  });

  // ─────────────────────────────────────────────────────────────────────────────
  // Config Actions
  // ─────────────────────────────────────────────────────────────────────────────

  async function fetchConfig(token: string): Promise<void> {
    loading.value = true;
    error.value = null;
    try {
      const response = await axios.get<LlmConfig>(`${API_BASE}/config`, {
        headers: authHeaders(token),
      });
      config.value = response.data;
    } catch (e) {
      error.value = e instanceof Error ? e.message : 'Failed to fetch config';
      throw e;
    } finally {
      loading.value = false;
    }
  }

  async function updateModel(token: string, model: string): Promise<ModelUpdateResponse> {
    loading.value = true;
    error.value = null;
    try {
      const response = await axios.put<ModelUpdateResponse>(
        `${API_BASE}/config`,
        null,
        {
          headers: authHeaders(token),
          params: { model },
        }
      );
      if (config.value) {
        config.value.current_model = model;
      }
      return response.data;
    } catch (e) {
      error.value = e instanceof Error ? e.message : 'Failed to update model';
      throw e;
    } finally {
      loading.value = false;
    }
  }

  // ─────────────────────────────────────────────────────────────────────────────
  // Prompt Actions
  // ─────────────────────────────────────────────────────────────────────────────

  async function fetchPrompts(token: string): Promise<void> {
    loading.value = true;
    error.value = null;
    try {
      const response = await axios.get<PromptTemplates>(`${API_BASE}/prompts`, {
        headers: authHeaders(token),
      });
      prompts.value = response.data;
    } catch (e) {
      error.value = e instanceof Error ? e.message : 'Failed to fetch prompts';
      throw e;
    } finally {
      loading.value = false;
    }
  }

  async function updatePrompt(
    token: string,
    type: PromptType,
    template: string,
    version: string,
    description?: string
  ): Promise<PromptUpdateResponse> {
    loading.value = true;
    error.value = null;
    try {
      const response = await axios.put<PromptUpdateResponse>(
        `${API_BASE}/prompts/${type}`,
        { template, version, description },
        { headers: authHeaders(token) }
      );
      return response.data;
    } catch (e) {
      error.value = e instanceof Error ? e.message : 'Failed to update prompt';
      throw e;
    } finally {
      loading.value = false;
    }
  }

  // ─────────────────────────────────────────────────────────────────────────────
  // Cache Actions
  // ─────────────────────────────────────────────────────────────────────────────

  async function fetchCacheStats(token: string): Promise<void> {
    loading.value = true;
    error.value = null;
    try {
      const response = await axios.get<CacheStats>(`${API_BASE}/cache/stats`, {
        headers: authHeaders(token),
      });
      cacheStats.value = response.data;
    } catch (e) {
      error.value = e instanceof Error ? e.message : 'Failed to fetch cache stats';
      throw e;
    } finally {
      loading.value = false;
    }
  }

  async function fetchCachedSummaries(
    token: string,
    params: {
      cluster_type?: ClusterType;
      validation_status?: ValidationStatus;
      page?: number;
      per_page?: number;
    } = {}
  ): Promise<PaginatedCacheSummaries> {
    const response = await axios.get<PaginatedCacheSummaries>(
      `${API_BASE}/cache/summaries`,
      {
        headers: authHeaders(token),
        params,
      }
    );
    return response.data;
  }

  async function clearCache(
    token: string,
    clusterType: ClusterType | 'all'
  ): Promise<CacheClearResponse> {
    const response = await axios.delete<CacheClearResponse>(`${API_BASE}/cache`, {
      headers: authHeaders(token),
      params: { cluster_type: clusterType },
    });
    return response.data;
  }

  async function updateValidationStatus(
    token: string,
    cacheId: number,
    action: 'validate' | 'reject'
  ): Promise<ValidationUpdateResponse> {
    const response = await axios.post<ValidationUpdateResponse>(
      `${API_BASE}/cache/${cacheId}/validate`,
      null,
      {
        headers: authHeaders(token),
        params: { action },
      }
    );
    return response.data;
  }

  // ─────────────────────────────────────────────────────────────────────────────
  // Regeneration Actions
  // ─────────────────────────────────────────────────────────────────────────────

  async function triggerRegeneration(
    token: string,
    clusterType: ClusterType | 'all',
    force = false
  ): Promise<RegenerationJobResponse> {
    const response = await axios.post<RegenerationJobResponse>(
      `${API_BASE}/regenerate`,
      null,
      {
        headers: authHeaders(token),
        params: { cluster_type: clusterType, force },
      }
    );
    return response.data;
  }

  // ─────────────────────────────────────────────────────────────────────────────
  // Log Actions
  // ─────────────────────────────────────────────────────────────────────────────

  async function fetchLogs(
    token: string,
    params: {
      cluster_type?: ClusterType;
      status?: LogStatus;
      from_date?: string;
      to_date?: string;
      page?: number;
      per_page?: number;
    } = {}
  ): Promise<PaginatedLogs> {
    const response = await axios.get<PaginatedLogs>(`${API_BASE}/logs`, {
      headers: authHeaders(token),
      params,
    });
    return response.data;
  }

  // ─────────────────────────────────────────────────────────────────────────────
  // Return
  // ─────────────────────────────────────────────────────────────────────────────

  return {
    // State (readonly)
    config: readonly(config),
    prompts: readonly(prompts),
    cacheStats: readonly(cacheStats),
    loading: readonly(loading),
    error: readonly(error),

    // Actions
    fetchConfig,
    updateModel,
    fetchPrompts,
    updatePrompt,
    fetchCacheStats,
    fetchCachedSummaries,
    clearCache,
    updateValidationStatus,
    triggerRegeneration,
    fetchLogs,
  };
}
```
  </action>
  <verify>
Run: cd /home/bernt-popp/development/sysndd/app && npm run type-check
Should pass with no TypeScript errors.
  </verify>
  <done>
useLlmAdmin.ts exists with all required API methods, passes TypeScript type-check.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add ManageLLM route and run linting</name>
  <files>app/src/router/routes.ts</files>
  <action>
1. **Add ManageLLM route** to app/src/router/routes.ts:
   - Find the admin routes section (around line 770, near ManagePubtator)
   - Add new route following the same pattern as other admin routes:

```typescript
  {
    path: '/ManageLLM',
    name: 'ManageLLM',
    component: () => import('@/views/admin/ManageLLM.vue'),
    meta: { sitemap: { ignoreRoute: true } },
    beforeEnter: (
      to: RouteLocationNormalized,
      from: RouteLocationNormalized,
      next: NavigationGuardNext
    ) => {
      const allowed_roles = ['Administrator'];
      let expires = 0;
      let timestamp = 0;
      let user_role = 'Viewer';

      if (localStorage.token) {
        expires = JSON.parse(localStorage.user).exp;
        user_role = JSON.parse(localStorage.user).user_role;
        timestamp = Math.floor(new Date().getTime() / 1000);
      }

      if (!localStorage.user || timestamp > expires || !allowed_roles.includes(user_role[0])) {
        next({ name: 'Login' });
      } else {
        next();
      }
    },
  },
```

2. **Run frontend linting and type-check:**
   - cd /home/bernt-popp/development/sysndd/app && npm run lint
   - cd /home/bernt-popp/development/sysndd/app && npm run type-check
   - Fix any issues

Note: The ManageLLM.vue component doesn't exist yet - it will be created in Plan 04. The route will cause a build warning but not a failure since it uses dynamic import.
  </action>
  <verify>
Run: cd /home/bernt-popp/development/sysndd/app && npm run lint && npm run type-check
Both should pass. Check that routes.ts contains '/ManageLLM' path.
  </verify>
  <done>
ManageLLM route added to routes.ts with Administrator-only access, frontend linting and type-check pass.
  </done>
</task>

</tasks>

<verification>
1. app/src/types/llm.ts exists with all interfaces
2. app/src/composables/useLlmAdmin.ts exists with all API methods
3. app/src/router/routes.ts contains ManageLLM route
4. TypeScript type-check passes (npm run type-check)
5. ESLint passes (npm run lint)
</verification>

<success_criteria>
- LlmConfig, PromptTemplate, CacheStats, CachedSummary, GenerationLog types defined
- useLlmAdmin composable exports all required methods
- Methods are type-safe with proper return types
- ManageLLM route requires Administrator role
- Frontend builds without type errors
</success_criteria>

<output>
After completion, create `.planning/phases/64-llm-admin-dashboard/64-03-SUMMARY.md`
</output>
