<!-- src/components/llm/LlmSummaryCard.vue -->
<template>
  <BCard v-if="summary" class="llm-summary-card mb-3" bg-variant="light">
    <template #header>
      <div class="d-flex justify-content-between align-items-center">
        <h6 class="mb-0">
          <i class="bi bi-stars me-2 text-warning" />
          AI-Generated Summary
        </h6>
        <!-- Judge verdict badge -->
        <BBadge
          v-if="judgeVerdict"
          v-b-tooltip.hover.left="judgeVerdictTooltip"
          :variant="judgeVerdictVariant"
          class="d-flex align-items-center"
        >
          <i v-if="judgeVerdict === 'accept'" class="bi bi-check-circle-fill me-1" />
          <i v-else-if="judgeVerdict === 'accept_with_corrections'" class="bi bi-check-circle me-1" />
          <i v-else-if="judgeVerdict === 'low_confidence'" class="bi bi-exclamation-triangle-fill me-1" />
          <i v-else-if="judgeVerdict === 'reject'" class="bi bi-x-circle-fill me-1" />
          {{ judgeVerdictLabel }}
        </BBadge>
      </div>
    </template>

    <!-- Summary text -->
    <p class="summary-text mb-3">{{ normalizedSummary?.summary }}</p>

    <!-- Key themes -->
    <div v-if="hasKeyThemes" class="mb-2">
      <strong class="me-2">Key themes:</strong>
      <BBadge
        v-for="theme in summary.key_themes"
        :key="theme"
        variant="secondary"
        class="me-1 mb-1"
      >
        {{ theme }}
      </BBadge>
    </div>

    <!-- Pathways -->
    <div v-if="hasPathways" class="mb-2">
      <strong class="me-2">Pathways:</strong>
      <BBadge
        v-for="pathway in summary.pathways"
        :key="pathway"
        variant="info"
        class="me-1 mb-1"
      >
        {{ pathway }}
      </BBadge>
    </div>

    <!-- Tags -->
    <div v-if="hasTags" class="mb-2">
      <strong class="me-2">Tags:</strong>
      <BBadge
        v-for="tag in summary.tags"
        :key="tag"
        variant="light"
        class="me-1 mb-1 border"
      >
        {{ tag }}
      </BBadge>
    </div>

    <!-- Clinical relevance (if present) -->
    <p v-if="normalizedSummary?.clinical_relevance" class="text-muted small mb-0 mt-3">
      <strong>Clinical relevance:</strong> {{ normalizedSummary.clinical_relevance }}
    </p>

    <template #footer>
      <small class="text-muted">
        <i
          v-b-tooltip.hover.top="provenanceTooltip"
          class="bi bi-info-circle me-1"
        />
        Generated by {{ modelName }} on {{ formattedDate }}
        <span
          v-if="validationStatus === 'validated'"
          v-b-tooltip.hover.top="validatedTooltip"
          class="ms-2"
          :class="{ 'cursor-pointer': hasCorrections }"
        >
          <i class="bi bi-check-circle-fill text-success" />
          Validated
          <i v-if="hasCorrections" class="bi bi-pencil-fill text-info ms-1" />
        </span>
        <span v-else-if="validationStatus === 'pending'" class="ms-2">
          <i class="bi bi-hourglass-split text-warning" />
          Pending review
        </span>
      </small>
    </template>
  </BCard>
</template>

<script lang="ts">
import { defineComponent, computed } from 'vue';
import type { PropType } from 'vue';
import { format } from 'date-fns';

/**
 * Interface for derived confidence from enrichment analysis
 */
interface DerivedConfidence {
  score: 'high' | 'medium' | 'low';
  avg_fdr: number;
  term_count: number;
}

/**
 * Interface for the summary JSON structure from the LLM
 */
interface SummaryJson {
  summary: string;
  key_themes?: string[];
  pathways?: string[];
  tags?: string[];
  clinical_relevance?: string;
  confidence?: string;
  derived_confidence?: DerivedConfidence;
  // Judge metadata (if present)
  llm_judge_verdict?: 'accept' | 'accept_with_corrections' | 'low_confidence' | 'reject';
  llm_judge_reasoning?: string;
  llm_judge_points?: number;
  corrections_applied?: boolean;
  corrections_made?: string[];
}

export default defineComponent({
  name: 'LlmSummaryCard',

  props: {
    /**
     * The structured summary data from the LLM
     */
    summary: {
      type: Object as PropType<SummaryJson | null>,
      default: null,
    },
    /**
     * Name of the model that generated the summary
     */
    modelName: {
      type: String,
      required: true,
    },
    /**
     * ISO date string when the summary was created
     */
    createdAt: {
      type: String,
      required: true,
    },
    /**
     * Validation status: 'pending', 'validated', or 'rejected'
     */
    validationStatus: {
      type: String as PropType<'pending' | 'validated' | 'rejected'>,
      default: 'pending',
    },
  },

  setup(props) {
    // Helper to normalize R JSON values (single values come as arrays)
    const normalize = <T,>(val: T | T[] | undefined): T | undefined => {
      if (val === undefined) return undefined;
      return Array.isArray(val) ? val[0] : val;
    };

    /**
     * Normalized summary with scalar fields extracted from R's array format
     */
    const normalizedSummary = computed<SummaryJson | null>(() => {
      if (!props.summary) return null;
      return {
        ...props.summary,
        summary: normalize(props.summary.summary) ?? '',
        clinical_relevance: normalize(props.summary.clinical_relevance),
      };
    });

    /**
     * Get derived confidence (objective, based on enrichment terms)
     * This is preferred over LLM self-assessment
     * Normalizes array values from R API (e.g., [0.001] -> 0.001)
     * Returns null if any required field is missing or invalid
     */
    const derivedConfidence = computed<DerivedConfidence | null>(() => {
      const dc = props.summary?.derived_confidence;
      if (!dc) return null;

      const score = normalize(dc.score);
      const avgFdr = normalize(dc.avg_fdr);
      const termCount = normalize(dc.term_count);

      // Validate all required fields are present and have valid types
      if (!score || typeof avgFdr !== 'number' || typeof termCount !== 'number') {
        return null;
      }

      return {
        score: score as 'high' | 'medium' | 'low',
        avg_fdr: avgFdr,
        term_count: termCount,
      };
    });

    /**
     * Confidence label (capitalized)
     */
    const confidenceLabel = computed<string>(() => {
      const score = derivedConfidence.value?.score;
      if (!score) return '';
      return score.charAt(0).toUpperCase() + score.slice(1);
    });

    /**
     * Bootstrap variant for confidence badge
     * High = success (green), Medium = warning (yellow), Low = danger (red)
     */
    type BadgeVariant = 'success' | 'warning' | 'danger' | 'secondary';
    const confidenceVariant = computed<BadgeVariant>(() => {
      const score = derivedConfidence.value?.score;
      switch (score) {
        case 'high':
          return 'success';
        case 'medium':
          return 'warning';
        case 'low':
          return 'danger';
        default:
          return 'secondary';
      }
    });

    /**
     * Tooltip explaining confidence score
     */
    const confidenceTooltip = computed<string>(() => {
      const dc = derivedConfidence.value;
      if (!dc) return '';

      const fdrFormatted = dc.avg_fdr < 0.001
        ? dc.avg_fdr.toExponential(2)
        : dc.avg_fdr.toFixed(4);

      return `${dc.score.toUpperCase()} confidence based on ${dc.term_count} significant terms (avg FDR: ${fdrFormatted})`;
    });

    /**
     * Format the creation date for display
     */
    const formattedDate = computed<string>(() => {
      if (!props.createdAt) return '';
      try {
        return format(new Date(props.createdAt), 'MMM d, yyyy');
      } catch {
        return props.createdAt;
      }
    });

    /**
     * Tooltip with AI provenance information
     */
    const provenanceTooltip = computed<string>(() => {
      const dc = derivedConfidence.value;
      let tooltip = `AI-generated summary from ${props.modelName}`;
      if (dc) {
        tooltip += `\nConfidence based on ${dc.term_count} enrichment terms`;
      }
      return tooltip;
    });

    /**
     * Check if key themes are present and non-empty
     */
    const hasKeyThemes = computed<boolean>(() => {
      return Array.isArray(props.summary?.key_themes) && props.summary.key_themes.length > 0;
    });

    /**
     * Check if pathways are present and non-empty
     */
    const hasPathways = computed<boolean>(() => {
      return Array.isArray(props.summary?.pathways) && props.summary.pathways.length > 0;
    });

    /**
     * Check if tags are present and non-empty
     */
    const hasTags = computed<boolean>(() => {
      return Array.isArray(props.summary?.tags) && props.summary.tags.length > 0;
    });

    /**
     * Judge verdict from LLM judge validation
     */
    const judgeVerdict = computed<string | null>(() => {
      return normalize(props.summary?.llm_judge_verdict) ?? null;
    });

    /**
     * Judge points (0-8 scale for functional, similar for phenotype)
     */
    const judgePoints = computed<number | null>(() => {
      const points = normalize(props.summary?.llm_judge_points);
      return typeof points === 'number' ? points : null;
    });

    /**
     * Whether corrections were applied by the judge
     */
    const hasCorrections = computed<boolean>(() => {
      return normalize(props.summary?.corrections_applied) === true;
    });

    /**
     * List of corrections made by the judge
     */
    const correctionsList = computed<string[]>(() => {
      const corrections = props.summary?.corrections_made;
      return Array.isArray(corrections) ? corrections : [];
    });

    /**
     * Judge verdict label for display - shows points/score only
     */
    const judgeVerdictLabel = computed<string>(() => {
      const verdict = judgeVerdict.value;
      const points = judgePoints.value;

      if (!verdict) return '';

      // Show points as score if available
      if (points !== null) {
        return `${points}/8`;
      }

      // Fallback to simple labels if no points
      switch (verdict) {
        case 'accept':
        case 'accept_with_corrections':
          return 'Verified';
        case 'low_confidence':
          return 'Low';
        case 'reject':
          return 'Rejected';
        default:
          return verdict;
      }
    });

    /**
     * Bootstrap variant for judge verdict badge
     */
    const judgeVerdictVariant = computed<BadgeVariant>(() => {
      const verdict = judgeVerdict.value;
      switch (verdict) {
        case 'accept':
          return 'success';
        case 'accept_with_corrections':
          return 'success'; // Still green, but with corrections indicator
        case 'low_confidence':
          return 'warning';
        case 'reject':
          return 'danger';
        default:
          return 'secondary';
      }
    });

    /**
     * Tooltip for judge verdict badge (shows points and reasoning)
     */
    const judgeVerdictTooltip = computed<string>(() => {
      const verdict = judgeVerdict.value;
      const reasoning = normalize(props.summary?.llm_judge_reasoning);
      const points = judgePoints.value;

      if (!verdict) return '';

      let tooltip = '';

      if (points !== null) {
        tooltip += `Score: ${points}/8 points\n`;
      }

      if (reasoning) {
        tooltip += `Reasoning: ${reasoning}`;
      }

      return tooltip.trim() || `Judge verdict: ${verdict}`;
    });

    /**
     * Tooltip for "Validated" status (shows corrections if any)
     */
    const validatedTooltip = computed<string>(() => {
      if (!hasCorrections.value || correctionsList.value.length === 0) {
        return 'Summary validated by LLM judge';
      }
      return `Validated with corrections:\n${correctionsList.value.join('\n')}`;
    });

    return {
      normalizedSummary,
      derivedConfidence,
      confidenceLabel,
      confidenceVariant,
      confidenceTooltip,
      formattedDate,
      provenanceTooltip,
      hasKeyThemes,
      hasPathways,
      hasTags,
      judgeVerdict,
      judgePoints,
      hasCorrections,
      correctionsList,
      judgeVerdictLabel,
      judgeVerdictVariant,
      judgeVerdictTooltip,
      validatedTooltip,
    };
  },
});
</script>

<style scoped>
.llm-summary-card {
  border-left: 4px solid var(--bs-warning);
}

.summary-text {
  line-height: 1.6;
  color: var(--bs-body-color);
}

.cursor-pointer {
  cursor: pointer;
}
</style>
